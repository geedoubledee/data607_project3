---
title: "Data 607 - Project 3 - Research"
author: "Glen Dale Davis, Coco Donovan, Alex Khaykin, Mohamed Hassan-El Serafi, Eddie Xu"
date: "2023-02-21"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load the Required Packages:

Below, the packages required for data analysis and visualization are loaded.

```{r packages, warning = FALSE, message = FALSE}
library(tidyverse)
library(magrittr)
library(DBI)
library(dbplyr)
library(RMariaDB)
```

## State the Research Question: 

W. Edwards Deming said, “In God we trust, all others must bring data.” Below, we will use data to explore the question, **“Which are the most valued data science skills?”**

## Create a Data Frame of Jobs Found via RSS Feed By Combining CSV Files and Removing Duplicates:

```{r jobs_df}
files <- list.files(pattern = ".csv$")
url_base <- "https://raw.githubusercontent.com/geedoubledee/data607_project3/main/"
jobs_df <- as.data.frame(matrix(nrow = 0, ncol = 11))
for (i in 1:length(files)){
    file <- paste(url_base, files[i], sep = "")
    csv <- read.csv(file = file, header = TRUE)
    jobs_df <- rbind(jobs_df, csv)
}
jobs_df <- jobs_df[!duplicated(jobs_df), ]

```

## Remove Unnecessary Columns in Jobs Data Frame and Rearrange Remaining Columns to Prepare the Data for the SQL Data Base:

```{r jobs_df_minimize}
jobs_df <- subset(jobs_df, select = -c(X, author, summary, content, extracted_content_url, published, created_at))
cols <- c("Job_id", "Site_id", "Job_title", "Job_url")
colnames(jobs_df) <- cols
rownames(jobs_df) <- NULL
jobs_df <- jobs_df[c("Job_id", "Job_title", "Job_url", "Site_id")]
jobs_df %<>%
    mutate(Job_id = row_number())
    mutate(Job_complete = 0)

```

## Scrape Each Unique Job Listing URL:

```{r scrape}

if (!dir.exists("jobs-text")){
    dir.create("jobs-txt")
}
loc <- paste(getwd(), "/jobs-txt", sep = "")

for (i in 1:length(jobs_df$Job_url)){
    httr::user_agent("Glen Davis")
    if (jobs_df[i, 5] == 0){
        dat <- try(xml2::read_html(jobs_df$Job_url[[i]]))
        if (inherits(dat, "try-error", which = FALSE)){
            next
        }
    }else{
        next
    }
    if (jobs_df[i, 4] == 2594160){ #ai-jobs.net is source
        desc <- xml2::xml_find_all(
            dat, "//div[contains(@id, 'job-description')]")
    }
    else if (jobs_df[i, 4] == 977141){ #python.org is source
        desc <- xml2::xml_find_all(
            dat, "//div[contains(@class, 'job-description')]")
    }
    else if (jobs_df[1,4] == 2594162){ #careercast it & eng is source
        desc <- xml2::xml_find_all(
            dat, "//div[contains(@class, 'arDetailDescriptionRow')]")
    }
    else if (jobs_df[1,4] == 1378327){ #jobs for r-users is source
        desc <- xml2::xml_find_all(
            dat, "//div[contains(@class, 'section_content')]")
    }
    else if (jobs_df[1,4] == 2593879){ #Indeed is source
        desc <- xml2::xml_find_all(
            dat, "//div[contains(@class, 'jobsearch-jobDescriptionText')]")
    }
    desc <- xml2::xml_text(desc)
    fn <- paste(loc, jobs_df[i, 1], ".txt", sept = "")
    writeLines(desc, con = fn)
    jobs_df[i, 5] <- 1
}

```

## Connect to the SQL Data Base:

```{r db_con}
con <- DBI::dbConnect(
  RMariaDB::MariaDB(),
  dbname = "dat_sci_jobs",
  username = "root",
  password = as.character(read.table("sql_db.txt", header = FALSE)),
  host = "35.227.102.234")

```

## Write to the SQL Data Base and Disconnect:

```{r db_write}
tables <- dbListTables(con)
dbAppendTable(con, "_Jobs", jobs_df)
dbDisconnect(con)

```

